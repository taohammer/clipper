{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more detailed guide refer to `tensorflow` or `pytorch` example or to the documentation on https://clipper.ai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "spark = SparkSession.builder.appName(\"example\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data and a simple model\n",
    "trainRDD = sc.parallelize([LabeledPoint(1.0, [1.0, 0.0, 3.0]), \n",
    "                           LabeledPoint(1.0, [1.0, 0.0, 4.0]), \n",
    "                           LabeledPoint(1.0, [1.0, 0.0, 5.0]),\n",
    "                           LabeledPoint(1.0, [2.0, 0.0, 5.0]),\n",
    "                           LabeledPoint(0.0, [4.0, 0.0, 2.0]),\n",
    "                           LabeledPoint(0.0, [4.0, 0.0, 1.0]),\n",
    "                           LabeledPoint(0.0, [5.0, 0.0, 1.5]),\n",
    "                           LabeledPoint(0.0, [3.0, 0.0, 1.0])])\n",
    "\n",
    "model = LogisticRegressionWithSGD.train(trainRDD, iterations=10)\n",
    "\n",
    "def shift(x):\n",
    "    return x - np.mean(x)\n",
    "\n",
    "def predict(spark, model, inputs):\n",
    "    return [str(model.predict(shift(x))) for x in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clipper_admin import ClipperConnection, DockerContainerManager\n",
    "from clipper_admin.deployers.pyspark import deploy_pyspark_model\n",
    "clipper_conn = ClipperConnection(DockerContainerManager())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19-05-31:10:37:56 INFO     [docker_container_manager.py:154] [default-cluster] Starting managed Redis instance in Docker\n",
      "19-05-31:10:37:58 INFO     [docker_container_manager.py:232] [default-cluster] Metric Configuration Saved at /tmp/tmp5l9n0w3g.yml\n",
      "19-05-31:10:37:59 INFO     [clipper_admin.py:143] [default-cluster] Clipper is running\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.start_clipper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19-05-31:10:38:00 INFO     [clipper_admin.py:156] [default-cluster] Successfully connected to Clipper cluster at localhost:1337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipper_conn.connect()\n",
    "clipper_conn.get_all_apps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipper_conn.get_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19-05-31:10:38:02 INFO     [clipper_admin.py:220] [default-cluster] Application pyspark-app was successfully registered\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.register_application(name=\"pyspark-app\", input_type=\"doubles\", \n",
    "                                  default_output=\"-1.0\", slo_micros=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19-05-31:10:38:06 INFO     [deployer_utils.py:41] Saving function to /tmp/tmpwrru4e6vclipper\n",
      "19-05-31:10:38:06 INFO     [deployer_utils.py:51] Serialized and supplied predict function\n",
      "19-05-31:10:38:10 INFO     [pyspark.py:234] Spark model saved\n",
      "19-05-31:10:38:10 INFO     [pyspark.py:248] Using Python 3.6 base image\n",
      "19-05-31:10:38:10 INFO     [clipper_admin.py:513] [default-cluster] Building model Docker image with model data from /tmp/tmpwrru4e6vclipper\n",
      "19-05-31:10:38:10 INFO     [clipper_admin.py:518] [default-cluster] Step 1/2 : FROM clipper/pyspark36-container:develop\n",
      "19-05-31:10:38:10 INFO     [clipper_admin.py:518] [default-cluster]  ---> dc5518780d68\n",
      "19-05-31:10:38:10 INFO     [clipper_admin.py:518] [default-cluster] Step 2/2 : COPY /tmp/tmpwrru4e6vclipper /model/\n",
      "19-05-31:10:38:10 INFO     [clipper_admin.py:518] [default-cluster]  ---> 17910751223a\n",
      "19-05-31:10:38:10 INFO     [clipper_admin.py:518] [default-cluster] Successfully built 17910751223a\n",
      "19-05-31:10:38:10 INFO     [clipper_admin.py:518] [default-cluster] Successfully tagged default-cluster-pyspark-mod:1\n",
      "19-05-31:10:38:10 INFO     [clipper_admin.py:520] [default-cluster] Pushing model Docker image to default-cluster-pyspark-mod:1\n",
      "19-05-31:10:38:12 INFO     [docker_container_manager.py:356] [default-cluster] Found 0 replicas for pyspark-mod:1. Adding 1\n",
      "19-05-31:10:38:13 INFO     [clipper_admin.py:697] [default-cluster] Successfully registered model pyspark-mod:1\n",
      "19-05-31:10:38:13 INFO     [clipper_admin.py:615] [default-cluster] Done deploying model pyspark-mod:1.\n"
     ]
    }
   ],
   "source": [
    "deploy_pyspark_model(\n",
    "    clipper_conn,\n",
    "    name=\"pyspark-mod\",\n",
    "    input_type=\"doubles\",\n",
    "    func=predict,\n",
    "    pyspark_model=model,\n",
    "    version='1',\n",
    "    sc=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19-05-31:10:38:15 INFO     [clipper_admin.py:282] [default-cluster] Model pyspark-mod is now linked to application pyspark-app\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.link_model_to_app(\n",
    "    app_name=\"pyspark-app\",\n",
    "    model_name=\"pyspark-mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pyspark-app']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipper_conn.get_all_apps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get query address\n",
    "query_address = clipper_conn.get_query_addr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_id': 0, 'output': 1, 'default': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a query\n",
    "import requests, json, numpy as np\n",
    "headers = {\"Content-type\": \"application/json\"}\n",
    "requests.post(\"http://\"+query_address+\"/pyspark-app/predict\", headers=headers, data=json.dumps({\n",
    "    \"input\": [2.1, 0.0, 4.2]})).json()\n",
    "# returns label `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_id': 1, 'output': 0, 'default': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(\"http://localhost:1337/pyspark-app/predict\", headers=headers, data=json.dumps({\n",
    "    \"input\": [4.1, 0.0, 1.2]})).json()\n",
    "# returns label `0`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19-05-31:10:38:54 INFO     [clipper_admin.py:323] Model pyspark-mod is now removed to application pyspark-app\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.unlink_model_from_app(model_name=\"pyspark-mod\", app_name=\"pyspark-app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19-05-31:10:39:05 INFO     [clipper_admin.py:1238] [default-cluster] Stopped all containers for these models and versions:\n",
      "{'pyspark-mod': ['1']}\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.stop_models('pyspark-mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19-05-31:10:39:05 INFO     [clipper_admin.py:239] [default-cluster] Application pyspark-app was successfully deleted\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.delete_application('pyspark-app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19-05-31:10:39:36 INFO     [clipper_admin.py:1324] [default-cluster] Stopped all Clipper cluster and all model containers\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.stop_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
